{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepProg.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNj1Miah+nQowcz1qbObW3F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UFNkeQAlhn-r","executionInfo":{"status":"ok","timestamp":1633590019856,"user_tz":-480,"elapsed":185469,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"7d279ab4-0e9d-42c1-869b-ed2a10fe5780"},"source":["# The downloading can take few minutes due to the size of th git project\n","!git clone https://github.com/lanagarmire/DeepProg.git\n","%cd DeepProg\n","\n","# (RECOMMENDED) to install the tested python library versions\n","!pip install -e . -r requirements_tested.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'DeepProg'...\n","remote: Enumerating objects: 2792, done.\u001b[K\n","remote: Counting objects: 100% (1167/1167), done.\u001b[K\n","remote: Compressing objects: 100% (753/753), done.\u001b[K\n","remote: Total 2792 (delta 758), reused 769 (delta 411), pack-reused 1625\u001b[K\n","Receiving objects: 100% (2792/2792), 150.45 MiB | 30.31 MiB/s, done.\n","Resolving deltas: 100% (1866/1866), done.\n","/content/DeepProg\n","Obtaining file:///content/DeepProg\n","Collecting tensorflow==2.4.1\n","  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n","\u001b[K     |████████████████████████████████| 394.3 MB 12 kB/s \n","\u001b[?25hCollecting keras==2.4.3\n","  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n","Collecting ray==0.8.4\n","  Downloading ray-0.8.4-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n","\u001b[K     |████████████████████████████████| 20.2 MB 53.7 MB/s \n","\u001b[?25hCollecting scikit-learn==0.23.2\n","  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 41.0 MB/s \n","\u001b[?25hCollecting scikit-survival==0.14.0\n","  Downloading scikit-survival-0.14.0.tar.gz (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 31.0 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting lifelines==0.25.5\n","  Downloading lifelines-0.25.5-py3-none-any.whl (345 kB)\n","\u001b[K     |████████████████████████████████| 345 kB 54.9 MB/s \n","\u001b[?25hCollecting scikit-optimize==0.8.1\n","  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 9.6 MB/s \n","\u001b[?25hCollecting mpld3==0.5.2\n","  Downloading mpld3-0.5.2.tar.gz (888 kB)\n","\u001b[K     |████████████████████████████████| 888 kB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from garmire-simdeep==2.7.2) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from garmire-simdeep==2.7.2) (1.4.1)\n","Collecting theano\n","  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 52.0 MB/s \n","\u001b[?25hCollecting simplejson\n","  Downloading simplejson-3.17.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n","\u001b[K     |████████████████████████████████| 129 kB 55.8 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from garmire-simdeep==2.7.2) (0.3.4)\n","Collecting colour\n","  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from garmire-simdeep==2.7.2) (0.11.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from garmire-simdeep==2.7.2) (0.8.9)\n","Collecting h5py~=2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 40.6 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (0.12.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.6.3)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (3.17.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.12.1)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (2.6.0)\n","Collecting tensorflow-estimator<2.5.0,>=2.4.0\n","  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 72.1 MB/s \n","\u001b[?25hCollecting grpcio~=1.32.0\n","  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 34.5 MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (3.3.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (3.7.4.3)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (0.37.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (0.2.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.12)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.15.0)\n","Collecting gast==0.3.3\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.1.2)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->-r requirements_tested.txt (line 2)) (3.13)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from ray==0.8.4->-r requirements_tested.txt (line 3)) (7.1.2)\n","Collecting py-spy>=0.2.0\n","  Downloading py_spy-0.3.10-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 37.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray==0.8.4->-r requirements_tested.txt (line 3)) (3.2.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 45.7 MB/s \n","\u001b[?25hRequirement already satisfied: google in /usr/local/lib/python3.7/dist-packages (from ray==0.8.4->-r requirements_tested.txt (line 3)) (2.0.3)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray==0.8.4->-r requirements_tested.txt (line 3)) (2.6.0)\n","Collecting redis>=3.3.2\n","  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 525 kB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting threadpoolctl>=2.0.0\n","  Using cached threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->-r requirements_tested.txt (line 4)) (1.0.1)\n","Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (1.2.7)\n","Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (1.0.31)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (2.7.3)\n","Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (1.1.5)\n","Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in /usr/local/lib/python3.7/dist-packages (from scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (0.6.2.post0)\n","Requirement already satisfied: patsy>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from lifelines==0.25.5->-r requirements_tested.txt (line 6)) (0.5.2)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from lifelines==0.25.5->-r requirements_tested.txt (line 6)) (3.2.2)\n","Collecting autograd-gamma>=0.3\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines==0.25.5->-r requirements_tested.txt (line 6)) (1.3)\n","Collecting pyaml>=16.9\n","  Downloading pyaml-21.8.3-py2.py3-none-any.whl (17 kB)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mpld3==0.5.2->-r requirements_tested.txt (line 8)) (2.11.3)\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->lifelines==0.25.5->-r requirements_tested.txt (line 6)) (0.16.0)\n","Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (2.0.7.post1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (0.70.12.2)\n","Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (2.1.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines==0.25.5->-r requirements_tested.txt (line 6)) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines==0.25.5->-r requirements_tested.txt (line 6)) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines==0.25.5->-r requirements_tested.txt (line 6)) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines==0.25.5->-r requirements_tested.txt (line 6)) (2.8.2)\n","Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (0.1.5.post0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->scikit-survival==0.14.0->-r requirements_tested.txt (line 5)) (2018.9)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.8.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (0.6.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (0.4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (4.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (3.1.1)\n","Collecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 68.3 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 77.9 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray==0.8.4->-r requirements_tested.txt (line 3)) (21.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google->ray==0.8.4->-r requirements_tested.txt (line 3)) (4.6.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1->-r requirements_tested.txt (line 1)) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mpld3==0.5.2->-r requirements_tested.txt (line 8)) (2.0.1)\n","Building wheels for collected packages: scikit-survival, mpld3, autograd-gamma, theano\n","  Building wheel for scikit-survival (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-survival: filename=scikit_survival-0.14.0-cp37-cp37m-linux_x86_64.whl size=4061619 sha256=29925dd1cb21990e14d1660a4e8ae3ee828677608d74445b15936f513c38f160\n","  Stored in directory: /root/.cache/pip/wheels/a2/3e/97/3722ba215d3dfe5429c1a7e4f24f535a3f46004fb29a16d505\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.5.2-py3-none-any.whl size=200643 sha256=98a6fc73ec43e977151667c2a9580329e6a6d3edf7bad0637825d417ee6237ee\n","  Stored in directory: /root/.cache/pip/wheels/11/af/f9/b3fc6166b9a794dcde7e64b183d48d495aa0f5e469d73ef385\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4049 sha256=5b104a219a2057b73794f5f70b48d06ec8d7b53730b4c2c0652880b6106f4b64\n","  Stored in directory: /root/.cache/pip/wheels/9f/01/ee/1331593abb5725ff7d8c1333aee93a50a1c29d6ddda9665c9f\n","  Building wheel for theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for theano: filename=Theano-1.0.5-py3-none-any.whl size=2668111 sha256=63df6aa1f953b79cb8d23873739bd1df756ac13d10e6a945f785c987164f2585\n","  Stored in directory: /root/.cache/pip/wheels/26/68/6f/745330367ce7822fe0cd863712858151f5723a0a5e322cc144\n","Successfully built scikit-survival mpld3 autograd-gamma theano\n","Installing collected packages: multidict, grpcio, yarl, threadpoolctl, tensorflow-estimator, h5py, gast, autograd-gamma, async-timeout, theano, tensorflow, simplejson, scikit-learn, redis, pyaml, py-spy, mpld3, lifelines, keras, colour, colorama, aiohttp, scikit-survival, scikit-optimize, ray, garmire-simdeep\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.41.0\n","    Uninstalling grpcio-1.41.0:\n","      Successfully uninstalled grpcio-1.41.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.6.0\n","    Uninstalling tensorflow-estimator-2.6.0:\n","      Successfully uninstalled tensorflow-estimator-2.6.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.6.0\n","    Uninstalling tensorflow-2.6.0:\n","      Successfully uninstalled tensorflow-2.6.0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.6.0\n","    Uninstalling keras-2.6.0:\n","      Successfully uninstalled keras-2.6.0\n","  Running setup.py develop for garmire-simdeep\n","Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 autograd-gamma-0.5.0 colorama-0.4.4 colour-0.1.5 garmire-simdeep-2.7.2 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 keras-2.4.3 lifelines-0.25.5 mpld3-0.5.2 multidict-5.2.0 py-spy-0.3.10 pyaml-21.8.3 ray-0.8.4 redis-3.5.3 scikit-learn-0.23.2 scikit-optimize-0.8.1 scikit-survival-0.14.0 simplejson-3.17.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0 theano-1.0.5 threadpoolctl-3.0.0 yarl-1.6.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["grpc"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdtWitrVikir","executionInfo":{"status":"ok","timestamp":1633590193274,"user_tz":-480,"elapsed":76432,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"4684cdfb-7e3b-4b91-b65f-f7e3e1bf3bbb"},"source":["%cd DeepProg\n","!python3 test/test_simdeep.py -v"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DeepProg\n","test_1_coxph_function (__main__.TestPackage)\n","test if the coxph function works ... #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","ok\n","test_4_keras_model_instantiation (__main__.TestPackage)\n","test if keras can be loaded and if that a model ... 2021-10-07 07:02:01.767790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2021-10-07 07:02:03.320955: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-10-07 07:02:03.349644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-10-07 07:02:03.466481: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-10-07 07:02:03.466557: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e7503d0901c3): /proc/driver/nvidia/version does not exist\n","2021-10-07 07:02:03.466963: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-10-07 07:02:03.467177: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-10-07 07:02:03.544627: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2021-10-07 07:02:03.545295: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n","2/2 [==============================] - 0s 1ms/step - loss: 5.3119\n","ok\n","test_5_one_simdeep_instance (__main__.TestPackage)\n","test one simdeep instance ... loading data...\n","rna_dummy.tsv loaded of dim:(50, 400)\n","meth_dummy.tsv loaded of dim:(50, 250)\n","mir_dummy.tsv loaded of dim:(50, 25)\n","data loaded in 0.017894744873046875 s\n","Not subsetting training dataset.\n","normalizing for RNA...\n","dim reduction for RNA...\n","normalizing for METH...\n","dim reduction for METH...\n","normalizing for MIR...\n","dim reduction for MIR...\n","creating autoencoder...\n","model for RNA created in 0.03521919250488281s !\n","creating autoencoder...\n","model for METH created in 0.035228729248046875s !\n","creating autoencoder...\n","model for MIR created in 0.030820846557617188s !\n","compiling deep model...\n","compilation done for key RNA!\n","compiling deep model...\n","compilation done for key METH!\n","compiling deep model...\n","compilation done for key MIR!\n","Epoch 1/3\n","2/2 - 1s - loss: 4.1754\n","Epoch 2/3\n","2/2 - 0s - loss: 3.8118\n","Epoch 3/3\n","2/2 - 0s - loss: 3.7491\n","fitting done for model RNA!\n","Epoch 1/3\n","2/2 - 1s - loss: 4.4735\n","Epoch 2/3\n","2/2 - 0s - loss: 4.3595\n","Epoch 3/3\n","2/2 - 0s - loss: 4.0407\n","fitting done for model METH!\n","Epoch 1/3\n","2/2 - 1s - loss: 4.6045\n","Epoch 2/3\n","2/2 - 0s - loss: 4.2698\n","Epoch 3/3\n","2/2 - 0s - loss: 4.0548\n","fitting done for model MIR!\n","number of components linked to survival found:1 for key RNA\n","number of components linked to survival found:8 for key METH\n","number of components linked to survival found:0 for key MIR\n","performing clustering on the omic model with the following key:['RNA', 'METH', 'MIR']\n","clustering done, labels ordered according to survival:\n","cluster label: 0\t number of samples:24\n","cluster label: 1\t number of samples:16\n","\n","\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_KM_plot_training_dataset.pdf\n","file written: /content/DeepProg/test/../examples/data//TestProject/TestProject_training_set_labels.tsv\n","Cox-PH p-value (Log-Rank) for the cluster labels: 1.3783094779559326e-09\n","classification method: ALL_FEATURES\n","number of features for the classifier: 120\n","classification analysis...\n","best params: {'C': 1000, 'class_weight': None, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': 10000}\n","cross val score: 0.475\n","classification score: 1.0\n","Scaling/Normalising dataset...\n","Scaling/Normalising dataset...\n","Scaling/Normalising dataset...\n","#### report of assigned cluster for full dataset:\n","class: 0, number of samples :28\n","class: 1, number of samples :22\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_KM_plot_full.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 4.700573245326887e-07\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 1.002828711990326e-06\n","file written: /content/DeepProg/test/../examples/data//TestProject/TestProject_full_labels.tsv\n","#### report of test fold cluster:):\n","class: 1, number of samples :6\n","class: 0, number of samples :4\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_KM_plot_test_fold.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 0.8659850083166286\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 0.7070073478931798\n","file written: /content/DeepProg/test/../examples/data//TestProject/TestProject_test_fold_labels.tsv\n","nb common features for the test set:400\n","Scaling/Normalising dataset...\n","classification for test set analysis...\n","classification method: ALL_FEATURES\n","number of features for the classifier: 40\n","best params: {'C': 1000, 'class_weight': None, 'gamma': 0.05, 'kernel': 'rbf', 'max_iter': 10000}\n","cross val score: 0.625\n","classification score: 1.0\n","#### report of assigned cluster:\n","class: 0, number of samples :31\n","class: 1, number of samples :19\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_dummy_KM_plot_test.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 3.6499895917756398e-06\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 4.548767989776771e-06\n","file written: /content/DeepProg/test/../examples/data//TestProject/TestProject_dummy_test_labels.tsv\n","#### asserting file: /content/DeepProg/test/../examples/data//TestProject/TestProject_KM_plot_training_dataset.pdf exists\n","ok\n","test_6_simdeep_boosting (__main__.TestPackage)\n","test simdeep boosting ... fit models...\n","Not subsetting training dataset.\n","model with random state:874 fitted\n","Not subsetting training dataset.\n","model with random state:664 fitted\n","Not subsetting training dataset.\n","model with random state:249 fitted\n","Results: [True, True, True]\n","3 models fitted\n","predict labels on full datasets...\n","#### Report of assigned cluster for the full training dataset:\n","class: 0, number of samples :25\n","class: 1, number of samples :25\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_KM_plot_boosting_full.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 9.19548448008069e-05\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 1.9219540048574315e-05\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_proba_KM_plot_boosting_full.pdf\n","Cox-PH categorical p-value (Log-Rank) for inferred labels: 9.19548448008069e-05\n","file written: /content/DeepProg/test/../examples/data//TestProject/TestProject_full_labels.tsv\n","Adj. Rand scores for full label: mean: 0.07262277951933127 std: 0.0738878559233592\n","silhouette score: mean: 0.3287540376186371 std :0.16120395064353943\n","calinski harabasz score: mean: 37.52886472746398 std :33.01928708864428\n","C-index results for test fold: mean 0.5490061237187674 std 0.017799986395455047\n","c-index results for full dataset: mean 0.6885895404120443 std 0.04599066239510782\n","Loading new test dataset dummy ...\n","Test dataset dummy loaded in 4.252213478088379 s\n","predict labels on test datasets...\n","#### Report of assigned cluster for TEST dataset dummy:\n","class: 0, number of samples :24\n","class: 1, number of samples :26\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_dummy_KM_plot_boosting_test.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 4.2637344951921546e-07\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 4.5286588970691995e-07\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_dummy_proba_KM_plot_boosting_test.pdf\n","Cox-PH categorical p-value (Log-Rank) for inferred labels: 3.2193478374522145e-08\n","file written: /content/DeepProg/test/../examples/data//TestProject/TestProject_dummy_test_labels.tsv\n","predict labels on test datasets...\n","#### Report of assigned cluster for TEST dataset dummy:\n","class: 0, number of samples :24\n","class: 1, number of samples :26\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_dummy_KM_plot_boosting_test.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 4.2637344951921546e-07\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 4.5286588970691995e-07\n","Figure saved in: /content/DeepProg/test/../examples/data//TestProject/TestProject_dummy_proba_KM_plot_boosting_test.pdf\n","Cox-PH categorical p-value (Log-Rank) for inferred labels: 3.2193478374522145e-08\n","file written: /content/DeepProg/test/../examples/data//TestProject/TestProject_dummy_test_labels.tsv\n","c-index for boosting test dataset:0.742472266244057\n","c-index proba for boosting test dataset:0.7908082408874801\n","c-index cat for boosting test dataset:0.768621236133122\n","Adj. Rand scores for test label: mean: 0.09537789141326518 std: 0.03488190482322073\n","ok\n","\n","----------------------------------------------------------------------\n","Ran 4 tests in 74.156s\n","\n","OK\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Zg_SS7TjtNu","executionInfo":{"status":"ok","timestamp":1633590268062,"user_tz":-480,"elapsed":517,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"9b7f8568-8f07-46e1-9ac6-f68156b4ba72"},"source":["%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PeDD5ZNRkUpl","executionInfo":{"status":"ok","timestamp":1633590312710,"user_tz":-480,"elapsed":21102,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"5fa96d9f-82f4-4f7f-ce4f-86d2ed28ff50"},"source":["# SimDeep class can be used to build one model with one autoencoder for each omic\n","from simdeep.simdeep_analysis import SimDeep\n","from simdeep.extract_data import LoadData\n","\n","help(SimDeep) # to see all the functions\n","help(LoadData) # to see all the functions related to loading datasets\n","\n","# Defining training datasets\n","from simdeep.config import TRAINING_TSV\n","from simdeep.config import SURVIVAL_TSV\n","# Location of the input matrices and survival file\n","from simdeep.config import PATH_DATA\n","\n","dataset = LoadData(training_tsv=TRAINING_TSV,\n","        survival_tsv=SURVIVAL_TSV,\n","        path_data=PATH_DATA)\n","\n","!mkdir TEST_DUMMY\n","# Defining the result path in which will be created an output folder\n","PATH_RESULTS = \"./TEST_DUMMY/\"\n","\n","# instantiate the model with the dummy example training dataset defined in the config file\n","simDeep = SimDeep(\n","        dataset=dataset,\n","        path_results=PATH_RESULTS,\n","        path_to_save_model=PATH_RESULTS, # This result path can be used to save the autoencoder\n","        )\n","\n","simDeep.load_training_dataset() # load the training dataset\n","simDeep.fit() # fit the model"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["#### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","Help on class SimDeep in module simdeep.simdeep_analysis:\n","\n","class SimDeep(simdeep.deepmodel_base.DeepBase)\n"," |  SimDeep(nb_clusters=2, pvalue_thres=0.01, cindex_thres=0.65, use_autoencoders=True, feature_surv_analysis=True, cluster_method='coxPHMixture', cluster_eval_method='silhouette', classifier_type='svm', project_name='test_dummy_dataset', path_results='./', cluster_array=[], nb_selected_features=50, mixture_params={'covariance_type': 'diag', 'max_iter': 1000, 'n_init': 100}, node_selection='Cox-PH', nb_threads_coxph=10, classification_method='ALL_FEATURES', load_existing_models=False, path_to_save_model='./', clustering_omics=[], metadata_usage=None, feature_selection_usage='individual', use_r_packages=False, seed=2020, alternative_embedding=None, do_KM_plot=True, verbose=True, _isboosting=False, dataset=None, kwargs_alternative_embedding={}, deep_model_additional_args={})\n"," |  \n"," |  Instanciate a new DeepProg instance.\n"," |  The default parameters are defined in the config.py file\n"," |  \n"," |  Parameters:\n"," |           :dataset: ExtractData instance. Default None (create a new dataset using the config variable)\n"," |           :nb_clusters: Number of clusters to search (default NB_CLUSTERS)\n"," |           :pvalue_thres: Pvalue threshold to include a feature  (default PVALUE_THRESHOLD)\n"," |           :clustering_omics: Which omics to use for clustering. If empty, then all the available omics will be used\n"," |           :cindex_thres: C-index threshold to include a feature. This parameter is used only if `node_selection` is set to \"C-index\" (default CINDEX_THRESHOLD)\n"," |           :cluster_method: Cluster method to use. possible choice ['mixture', 'kmeans']. (default CLUSTER_METHOD)\n"," |           :cluster_eval_method: Cluster evaluation method to use in case the `cluster_array` parameter is a list of possible K. Possible choice ['bic', 'silhouette', 'calinski'] (default CLUSTER_EVAL_METHOD)\n"," |           :classifier_type: Type of classifier to use. Possible choice ['svm', 'clustering']. If 'clustering' is selected, The predict method of the clustering algoritm is used  (default CLASSIFIER_TYPE)\n"," |           :project_name: Name of the project. This name will be used to save the output files and create the output folder (default PROJECT_NAME)\n"," |           :path_results: Result folder path used to save the output files (default PATH_RESULTS)\n"," |           :cluster_array: Array of possible number of clusters to try. If set, `nb_clusters` is ignored (default CLUSTER_ARRAY)\n"," |           :nb_selected_features: Number of selected features to construct classifiers (default NB_SELECTED_FEATURES)\n"," |           :mixture_params: Dictionary of parameters used to instanciate the Gaussian mixture algorithm (default MIXTURE_PARAMS)\n"," |           :node_selection: Mehtod to select new features. possible choice ['Cox-PH', 'C-index']. (default NODES_SELECTION)\n"," |           :nb_threads_coxph: Number of python processes to use to compute individual survival models in parallel (default NB_THREADS_COXPH)\n"," |           :classification_method: Possible choice  ['ALL_FEATURES', 'SURVIVAL_FEATURES']. If 'SURVIVAL_FEATURES' is selected, the classifiers are built using survival features  (default CLASSIFICATION_METHOD)\n"," |           :load_existing_models: (default LOAD_EXISTING_MODELS)\n"," |           :path_to_save_model: (default PATH_TO_SAVE_MODEL)\n"," |           :metadata_usage: Meta data usage with survival models (if metadata_tsv provided as argument to the dataset). Possible choice are [None, False, 'labels', 'new-features', 'all', True] (True is the same as all)\n"," |           :feature_selection_usage: selection method for survival features ('individual' or 'lasso')\n"," |           :alternative_embedding: alternative external embedding to use instead of builfing autoencoders (default None)\n"," |           :kwargs_alternative_embedding: parameters for external embedding fitting\n"," |  \n"," |  Method resolution order:\n"," |      SimDeep\n"," |      simdeep.deepmodel_base.DeepBase\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, nb_clusters=2, pvalue_thres=0.01, cindex_thres=0.65, use_autoencoders=True, feature_surv_analysis=True, cluster_method='coxPHMixture', cluster_eval_method='silhouette', classifier_type='svm', project_name='test_dummy_dataset', path_results='./', cluster_array=[], nb_selected_features=50, mixture_params={'covariance_type': 'diag', 'max_iter': 1000, 'n_init': 100}, node_selection='Cox-PH', nb_threads_coxph=10, classification_method='ALL_FEATURES', load_existing_models=False, path_to_save_model='./', clustering_omics=[], metadata_usage=None, feature_selection_usage='individual', use_r_packages=False, seed=2020, alternative_embedding=None, do_KM_plot=True, verbose=True, _isboosting=False, dataset=None, kwargs_alternative_embedding={}, deep_model_additional_args={})\n"," |  \n"," |  compute_c_indexes_for_full_dataset(self)\n"," |      return c-index using labels as predicat\n"," |  \n"," |  compute_c_indexes_for_test_dataset(self)\n"," |      return c-index using labels as predicat\n"," |  \n"," |  compute_c_indexes_for_test_fold_dataset(self)\n"," |      return c-index using labels as predicat\n"," |  \n"," |  compute_c_indexes_for_training_dataset(self)\n"," |      return c-index using labels as predicat\n"," |  \n"," |  compute_c_indexes_multiple_for_test_dataset(self)\n"," |      return c-index using labels as predicat\n"," |  \n"," |  compute_c_indexes_multiple_for_test_fold_dataset(self)\n"," |      return c-index using test-fold labels as predicat\n"," |  \n"," |  compute_feature_scores(self, use_ref=False)\n"," |  \n"," |  compute_feature_scores_per_cluster(self, use_ref=False, pval_thres=0.01)\n"," |  \n"," |  evalutate_cluster_performance(self)\n"," |  \n"," |  fit(self)\n"," |      main function\n"," |      I) construct an autoencoder or fit alternative embedding\n"," |      II) predict nodes linked with survival (if active)\n"," |      and III) do clustering\n"," |  \n"," |  fit_classification_model(self)\n"," |  \n"," |  fit_classification_test_model(self)\n"," |  \n"," |  fit_on_pretrained_label_file(self, label_file)\n"," |      fit a deepprog simdeep model without training autoencoder but just using a ID->labels file to train a classifier\n"," |  \n"," |  load_new_test_dataset(self, tsv_dict, fname_key=None, path_survival_file=None, normalization=None, survival_flag=None, metadata_file=None)\n"," |  \n"," |  look_for_prediction_nodes(self, keys=None)\n"," |      detect nodes from the autoencoder that predict a\n"," |      high c-index scores using label from the retained test fold\n"," |  \n"," |  look_for_survival_nodes(self, keys=None)\n"," |      detect nodes from the autoencoder significantly\n"," |      linked with survival through coxph regression\n"," |  \n"," |  plot_kernel_for_test_sets(self, dataset=None, labels=None, labels_proba=None, test_labels=None, test_labels_proba=None, define_as_main_kernel=False, use_main_kernel=False, activities=None, activities_test=None, key='')\n"," |  \n"," |  plot_supervised_kernel_for_test_sets(self, labels=None, labels_proba=None, dataset=None, key='', use_main_kernel=False, test_labels=None, test_labels_proba=None, define_as_main_kernel=False)\n"," |  \n"," |  predict_labels(self)\n"," |      predict labels from training set\n"," |      using K-Means algorithm on the node activities,\n"," |      using only nodes linked to survival\n"," |  \n"," |  predict_labels_on_full_dataset(self)\n"," |  \n"," |  predict_labels_on_test_dataset(self)\n"," |  \n"," |  predict_labels_on_test_fold(self)\n"," |  \n"," |  predict_labels_using_external_labels(self, labels, labels_proba)\n"," |  \n"," |  predict_nodes_activities(self, matrix_array)\n"," |  \n"," |  write_feature_score_per_cluster(self)\n"," |  \n"," |  write_feature_scores(self)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from simdeep.deepmodel_base.DeepBase:\n"," |  \n"," |  compile_models(self)\n"," |      define the optimizer and the loss function\n"," |      compile the model and ready to fit the data!\n"," |  \n"," |  construct_autoencoders(self)\n"," |      main class to create the autoencoder\n"," |  \n"," |  construct_supervized_network(self, objective)\n"," |      main class to create the autoencoder\n"," |  \n"," |  create_autoencoders(self, matrix_out=None)\n"," |  \n"," |  embedding_predict(self, key, matrix)\n"," |      Predict the output value using the matrix as input and\n"," |      the fitted embedding model from self.alternative_embedding_array\n"," |  \n"," |  encoder_input_shape(self, key)\n"," |      Predict the output value using the matrix as input for the encoder from key\n"," |  \n"," |  encoder_predict(self, key, matrix)\n"," |      Predict the output value using the matrix as input for the encoder from key\n"," |  \n"," |  fit_alternative_embedding(self)\n"," |  \n"," |  fit_autoencoders(self, objective=None)\n"," |      fit the autoencoder using the training matrix\n"," |  \n"," |  load_encoders(self, fname='encoder.h5')\n"," |      Load a keras model from the self.path_to_save_model directory\n"," |      :fname: str    the name of the file to load\n"," |  \n"," |  load_test_dataset(self)\n"," |      load test dataset and test surival\n"," |  \n"," |  load_training_dataset(self)\n"," |      load training dataset and surival\n"," |  \n"," |  save_encoders(self, fname='encoder.h5')\n"," |      Save a keras model in the self.path_to_save_model directory\n"," |      :fname: str    the name of the file to save the model\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from simdeep.deepmodel_base.DeepBase:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n","Help on class LoadData in module simdeep.extract_data:\n","\n","class LoadData(builtins.object)\n"," |  LoadData(path_data='/content/DeepProg/simdeep/../examples/data/', training_tsv={'GE': 'rna_dummy.tsv', 'MIR': 'mir_dummy.tsv', 'METH': 'meth_dummy.tsv'}, survival_tsv='survival_dummy.tsv', metadata_tsv=None, metadata_test_tsv=None, test_tsv={'MIR': 'mir_test_dummy.tsv'}, survival_tsv_test='survival_test_dummy.tsv', cross_validation_instance=KFold(n_splits=5, random_state=1, shuffle=True), test_fold=0, stack_multi_omic=False, fill_unkown_feature_with_0=True, normalization={'NB_FEATURES_TO_KEEP': 100, 'TRAIN_MIN_MAX': False, 'TRAIN_ROBUST_SCALE': False, 'TRAIN_ROBUST_SCALE_TWO_WAY': False, 'TRAIN_MAD_SCALE': False, 'TRAIN_QUANTILE_TRANSFORM': False, 'TRAIN_NORM_SCALE': False, 'TRAIN_RANK_NORM': True, 'TRAIN_CORR_REDUCTION': True, 'TRAIN_CORR_RANK_NORM': True}, survival_flag={'patient_id': 'barcode', 'survival': 'days', 'event': 'recurrence'}, subset_training_with_meta={}, _autoencoder_parameters={}, verbose=True)\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __del__(self)\n"," |  \n"," |  __init__(self, path_data='/content/DeepProg/simdeep/../examples/data/', training_tsv={'GE': 'rna_dummy.tsv', 'MIR': 'mir_dummy.tsv', 'METH': 'meth_dummy.tsv'}, survival_tsv='survival_dummy.tsv', metadata_tsv=None, metadata_test_tsv=None, test_tsv={'MIR': 'mir_test_dummy.tsv'}, survival_tsv_test='survival_test_dummy.tsv', cross_validation_instance=KFold(n_splits=5, random_state=1, shuffle=True), test_fold=0, stack_multi_omic=False, fill_unkown_feature_with_0=True, normalization={'NB_FEATURES_TO_KEEP': 100, 'TRAIN_MIN_MAX': False, 'TRAIN_ROBUST_SCALE': False, 'TRAIN_ROBUST_SCALE_TWO_WAY': False, 'TRAIN_MAD_SCALE': False, 'TRAIN_QUANTILE_TRANSFORM': False, 'TRAIN_NORM_SCALE': False, 'TRAIN_RANK_NORM': True, 'TRAIN_CORR_REDUCTION': True, 'TRAIN_CORR_RANK_NORM': True}, survival_flag={'patient_id': 'barcode', 'survival': 'days', 'event': 'recurrence'}, subset_training_with_meta={}, _autoencoder_parameters={}, verbose=True)\n"," |      class to extract data\n"," |      :training_matrices: dict(matrice_type, path to the tsv file)\n"," |      \n"," |      :path_data: str    path to the folder containing the data\n"," |      :training_tsv: dict    dict('data type', 'name of the tsv file')\n"," |      :survival_tsv: str    name of the tsv file containing the survival data\n"," |                            of the training set\n"," |      :survival_tsv_test: str    name of the tsv file containing the survival data\n"," |                                 of the test set\n"," |      :metadata_tsv: str         name of the file containing metadata\n"," |      :metadata_test_tsv: str         name of the file containing metadata of the test set\n"," |      :tsv_test: str    name of the file containing the test dataset\n"," |      :data_type_test: str    name of the data type of the test set\n"," |                              must match a key existing in training_tsv\n"," |  \n"," |  create_a_cv_split(self)\n"," |  \n"," |  load_array(self)\n"," |  \n"," |  load_matrix_full(self)\n"," |  \n"," |  load_matrix_test(self, normalization=None)\n"," |  \n"," |  load_matrix_test_fold(self)\n"," |  \n"," |  load_meta_data(self, sep='\\t')\n"," |  \n"," |  load_meta_data_test(self, metadata_file='', sep='\\t')\n"," |  \n"," |  load_new_test_dataset(self, tsv_dict, path_survival_file=None, survival_flag=None, normalization=None, metadata_file=None)\n"," |  \n"," |  load_survival(self)\n"," |  \n"," |  load_survival_test(self, survival_flag=None)\n"," |  \n"," |  normalize_training_array(self)\n"," |  \n"," |  reorder_matrix_array(self, new_sample_ids)\n"," |  \n"," |  save_ref_matrix(self, path_folder, project_name)\n"," |  \n"," |  subset_training_sets(self, change_cv=False)\n"," |  \n"," |  transform_matrices(self, matrix_ref, matrix, key, normalization=None)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n","loading data...\n","rna_dummy.tsv loaded of dim:(50, 400)\n","mir_dummy.tsv loaded of dim:(50, 25)\n","meth_dummy.tsv loaded of dim:(50, 250)\n","data loaded in 0.020722150802612305 s\n","Not subsetting training dataset.\n","normalizing for GE...\n","dim reduction for GE...\n","normalizing for MIR...\n","dim reduction for MIR...\n","normalizing for METH...\n","dim reduction for METH...\n","creating autoencoder...\n","model for GE created in 0.07737898826599121s !\n","creating autoencoder...\n","model for MIR created in 0.034757375717163086s !\n","creating autoencoder...\n","model for METH created in 0.04998612403869629s !\n","compiling deep model...\n","compilation done for key GE!\n","compiling deep model...\n","compilation done for key MIR!\n","compiling deep model...\n","compilation done for key METH!\n","Epoch 1/10\n","2/2 - 1s - loss: 3.9187\n","Epoch 2/10\n","2/2 - 0s - loss: 3.7006\n","Epoch 3/10\n","2/2 - 0s - loss: 3.5758\n","Epoch 4/10\n","2/2 - 0s - loss: 3.1821\n","Epoch 5/10\n","2/2 - 0s - loss: 2.9390\n","Epoch 6/10\n","2/2 - 0s - loss: 2.7253\n","Epoch 7/10\n","2/2 - 0s - loss: 2.4776\n","Epoch 8/10\n","2/2 - 0s - loss: 2.4481\n","Epoch 9/10\n","2/2 - 0s - loss: 2.1183\n","Epoch 10/10\n","2/2 - 0s - loss: 2.2562\n","fitting done for model GE!\n","Epoch 1/10\n","2/2 - 1s - loss: 3.8804\n","Epoch 2/10\n","2/2 - 0s - loss: 3.6391\n","Epoch 3/10\n","2/2 - 0s - loss: 3.2586\n","Epoch 4/10\n","2/2 - 0s - loss: 3.2488\n","Epoch 5/10\n","2/2 - 0s - loss: 2.8230\n","Epoch 6/10\n","2/2 - 0s - loss: 2.7037\n","Epoch 7/10\n","2/2 - 0s - loss: 2.6223\n","Epoch 8/10\n","2/2 - 0s - loss: 2.4900\n","Epoch 9/10\n","2/2 - 0s - loss: 2.2686\n","Epoch 10/10\n","2/2 - 0s - loss: 2.1889\n","fitting done for model MIR!\n","Epoch 1/10\n","2/2 - 1s - loss: 4.3824\n","Epoch 2/10\n","2/2 - 0s - loss: 4.1501\n","Epoch 3/10\n","2/2 - 0s - loss: 3.7829\n","Epoch 4/10\n","2/2 - 0s - loss: 3.6647\n","Epoch 5/10\n","2/2 - 0s - loss: 3.5731\n","Epoch 6/10\n","2/2 - 0s - loss: 3.3068\n","Epoch 7/10\n","2/2 - 0s - loss: 3.0986\n","Epoch 8/10\n","2/2 - 0s - loss: 2.9887\n","Epoch 9/10\n","2/2 - 0s - loss: 2.9391\n","Epoch 10/10\n","2/2 - 0s - loss: 2.7267\n","fitting done for model METH!\n","number of components linked to survival found:1 for key GE\n","number of components linked to survival found:0 for key MIR\n","number of components linked to survival found:1 for key METH\n","performing clustering on the omic model with the following key:['GE', 'MIR', 'METH']\n","clustering done, labels ordered according to survival:\n","cluster label: 0\t number of samples:24\n","cluster label: 1\t number of samples:16\n","\n","\n","Figure saved in: ./TEST_DUMMY//test_dummy_dataset_KM_plot_training_dataset.pdf\n","file written: ./TEST_DUMMY//test_dummy_dataset_training_set_labels.tsv\n","Cox-PH p-value (Log-Rank) for the cluster labels: 0.00037905764502480383\n","classification method: ALL_FEATURES\n","number of features for the classifier: 120\n","classification analysis...\n","best params: {'C': 750, 'class_weight': None, 'gamma': 0.0001, 'kernel': 'rbf', 'max_iter': 10000}\n","cross val score: 0.75\n","classification score: 1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eF6OVoROkapq","executionInfo":{"status":"ok","timestamp":1633590356232,"user_tz":-480,"elapsed":2057,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"08eea8fd-5ac7-49bd-fc62-29a9f53d4f7c"},"source":["# Defining test datasets\n","from simdeep.config import TEST_TSV\n","from simdeep.config import SURVIVAL_TSV_TEST\n","\n","simDeep.load_new_test_dataset(\n","    TEST_TSV,\n","    fname_key='dummy',\n","    path_survival_file=SURVIVAL_TSV_TEST, # [OPTIONAL] test survival file useful to compute accuracy of test dataset\n","\n","    )\n","\n","# The test set is a dummy rna expression (generated randomly)\n","print(simDeep.dataset.test_tsv) # Defined in the config file\n","# The data type of the test set is also defined to match an existing type\n","print(simDeep.dataset.data_type) # Defined in the config file\n","simDeep.predict_labels_on_test_dataset() # Perform the classification analysis and label the set dataset\n","\n","print(simDeep.test_labels)\n","print(simDeep.test_labels_proba)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nb common features for the test set:25\n","Scaling/Normalising dataset...\n","{'MIR': 'mir_test_dummy.tsv'}\n","['GE', 'MIR', 'METH']\n","classification for test set analysis...\n","classification method: ALL_FEATURES\n","number of features for the classifier: 40\n","best params: {'C': 250, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf', 'max_iter': 10000}\n","cross val score: 0.525\n","classification score: 0.825\n","#### report of assigned cluster:\n","class: 0, number of samples :29\n","class: 1, number of samples :21\n","Figure saved in: ./TEST_DUMMY//test_dummy_dataset_dummy_KM_plot_test.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 0.010899763597993377\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 0.017350429183963262\n","file written: ./TEST_DUMMY//test_dummy_dataset_dummy_test_labels.tsv\n","[0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1\n"," 0 0 1 0 0 0 0 1 1 1 0 1 1]\n","[[0.56872538 0.43127462]\n"," [0.56874075 0.43125925]\n"," [0.59011107 0.40988893]\n"," [0.57910476 0.42089524]\n"," [0.57397527 0.42602473]\n"," [0.56872503 0.43127497]\n"," [0.58164548 0.41835452]\n"," [0.57056924 0.42943076]\n"," [0.62950171 0.37049829]\n"," [0.63026948 0.36973052]\n"," [0.62951356 0.37048644]\n"," [0.56872117 0.43127883]\n"," [0.60604722 0.39395278]\n"," [0.57027914 0.42972086]\n"," [0.56874153 0.43125847]\n"," [0.5788597  0.4211403 ]\n"," [0.6215209  0.3784791 ]\n"," [0.59893216 0.40106784]\n"," [0.60664685 0.39335315]\n"," [0.58644018 0.41355982]\n"," [0.64088031 0.35911969]\n"," [0.62596015 0.37403985]\n"," [0.62724064 0.37275936]\n"," [0.57080446 0.42919554]\n"," [0.56874151 0.43125849]\n"," [0.61124074 0.38875926]\n"," [0.61264241 0.38735759]\n"," [0.56862554 0.43137446]\n"," [0.63752084 0.36247916]\n"," [0.59723099 0.40276901]\n"," [0.56873523 0.43126477]\n"," [0.57401349 0.42598651]\n"," [0.60922087 0.39077913]\n"," [0.59391695 0.40608305]\n"," [0.61292691 0.38707309]\n"," [0.57476846 0.42523154]\n"," [0.62951013 0.37048987]\n"," [0.58589356 0.41410644]\n"," [0.59500994 0.40499006]\n"," [0.62949587 0.37050413]\n"," [0.59746645 0.40253355]\n"," [0.56874195 0.43125805]\n"," [0.56865169 0.43134831]\n"," [0.59017542 0.40982458]\n"," [0.61825608 0.38174392]\n"," [0.6295092  0.3704908 ]\n"," [0.60283273 0.39716727]\n"," [0.57459654 0.42540346]\n"," [0.63342639 0.36657361]\n"," [0.62950464 0.37049536]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxgCPLgckp7T","executionInfo":{"status":"ok","timestamp":1633590533075,"user_tz":-480,"elapsed":682,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"d7232a8b-85a4-45d7-b78a-c6dbe3410c95"},"source":["from simdeep.simdeep_boosting import SimDeepBoosting\n","\n","help(SimDeepBoosting)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on class SimDeepBoosting in module simdeep.simdeep_boosting:\n","\n","class SimDeepBoosting(builtins.object)\n"," |  SimDeepBoosting(nb_it=10, do_KM_plot=True, distribute=False, nb_threads=5, class_selection='mean', model_thres=0.05, verbose=True, seed=None, project_name='test_dummy_dataset_boosting', use_autoencoders=True, feature_surv_analysis=True, split_n_fold=5, path_results='./', nb_clusters=2, epochs=10, normalization={'NB_FEATURES_TO_KEEP': 100, 'TRAIN_MIN_MAX': False, 'TRAIN_ROBUST_SCALE': False, 'TRAIN_ROBUST_SCALE_TWO_WAY': False, 'TRAIN_MAD_SCALE': False, 'TRAIN_QUANTILE_TRANSFORM': False, 'TRAIN_NORM_SCALE': False, 'TRAIN_RANK_NORM': True, 'TRAIN_CORR_REDUCTION': True, 'TRAIN_CORR_RANK_NORM': True}, nb_selected_features=50, cluster_method='coxPHMixture', pvalue_thres=0.01, classification_method='ALL_FEATURES', new_dim=100, training_tsv={'GE': 'rna_dummy.tsv', 'MIR': 'mir_dummy.tsv', 'METH': 'meth_dummy.tsv'}, metadata_usage=None, survival_tsv='survival_dummy.tsv', metadata_tsv=None, subset_training_with_meta={}, survival_flag={'patient_id': 'barcode', 'survival': 'days', 'event': 'recurrence'}, path_data='/content/DeepProg/simdeep/../examples/data/', level_dims_in=(), level_dims_out=(), loss='binary_crossentropy', optimizer='adam', act_reg=False, w_reg=False, dropout=0.5, data_split=None, node_selection='Cox-PH', cindex_thres=0.65, activation='tanh', clustering_omics=[], path_to_save_model='./', feature_selection_usage='individual', use_r_packages=False, alternative_embedding=None, kwargs_alternative_embedding={}, **additional_dataset_args)\n"," |  \n"," |  Instanciate a new DeepProg Boosting instance.\n"," |  The default parameters are defined in the config.py file\n"," |  \n"," |  Parameters:\n"," |          :nb_it: Number of models to construct\n"," |          :do_KM_plot: Plot Kaplan-Meier (default: True)\n"," |          :distribute: Distribute DeepProg using ray (default:  False)\n"," |          :nb_threads: Number of python threads to use to compute parallel Cox-PH\n"," |          :class_selection: Consensus score to agglomerate DeepProg Instance {'mean', 'max', 'weighted_mean', 'weighted_max'} (default: 'mean')\n"," |          :model_thres: Cox-PH p-value threshold to reject a model for DeepProg Boosting module\n"," |          :verbose: Verobosity (Default: True)\n"," |          :seed: Seed defining the  random split of the training dataset (Default: None).\n"," |          :project_name: Project name used to save files\n"," |          :use_autoencoders: Use autoencoder steps to embed the data (default: True)\n"," |          :feature_surv_analysis: Use individual survival feature detection to filter out features (default: True)\n"," |          :split_n_fold: For each instance, the original dataset is split in folds and one fold is left\n"," |          :path_results: Path to create a result folder\n"," |          :nb_clusters: Number of clusters to use\n"," |          :epochs: Number of epochs\n"," |          :normalization: Normalisation procedure to use. See config.py file for details\n"," |          :nb_selected_features: Number of top features selected for classification\n"," |          :cluster_method: Clustering method. possible choice: ['mixture', 'kmeans', 'coxPH'] or class instance having fit and fit_proba attributes\n"," |          :pvalue_thres: Threshold for survival significance to set a node as valid\n"," |          :classification_method: Possible choice: {'ALL_FEATURES', 'SURVIVAL_FEATURES'} (default: 'ALL_FEATURES')\n"," |          :new_dim: Size of the new embedding\n"," |          :training_tsv: Input matrix files\n"," |          :survival_tsv: Input surival file\n"," |          :survival_flag: Survival flag to use\n"," |          :path_data: Path of the input file\n"," |          :level_dims_in: Autoencoder node layers before the middle layer (default: [])\n"," |          :level_dims_out: Autoencoder node layers after the middle layer (default: [])\n"," |          :loss: Loss function to minimize (default: 'binary_crossentropy')\n"," |          :optimizer: Optimizer (default: adam)\n"," |          :act_reg: L2 Regularization constant on the node activity (default: False)\n"," |          :w_reg: L1 Regularization constant on the weight (default: False)\n"," |          :dropout: Percentage of edges being dropout at each training iteration (None for no dropout) (default: 0.5)\n"," |          :data_split: Fraction of the dataset to be used as test set when building the autoencoder (default: None)\n"," |          :node_selection: possible choice: {'Cox-PH', 'C-index'} (default: Cox-PH)\n"," |          :cindex_thres: Valid if 'c-index' is chosen (default: 0.65)\n"," |          :activation: Activation function (default: 'tanh')\n"," |          :clustering_omics: Which omics to use for clustering. If empty, then all the available omics will be used (default [] => all)\n"," |          :path_to_save_model: path to save the model\n"," |          :metadata_usage: Meta data usage with survival models (if metadata_tsv provided as argument to the dataset). Possible choice are [None, False, 'labels', 'new-features', 'all', True] (True is the same as all)\n"," |          :subset_training_with_meta: Use a metadata key-value dict {meta_key:value} to subset the training sets\n"," |          :alternative_embedding: alternative external embedding to use instead of building autoencoders (default None)\n"," |          :kwargs_alternative_embedding: parameters for external embedding fitting\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __del__(self)\n"," |  \n"," |  __init__(self, nb_it=10, do_KM_plot=True, distribute=False, nb_threads=5, class_selection='mean', model_thres=0.05, verbose=True, seed=None, project_name='test_dummy_dataset_boosting', use_autoencoders=True, feature_surv_analysis=True, split_n_fold=5, path_results='./', nb_clusters=2, epochs=10, normalization={'NB_FEATURES_TO_KEEP': 100, 'TRAIN_MIN_MAX': False, 'TRAIN_ROBUST_SCALE': False, 'TRAIN_ROBUST_SCALE_TWO_WAY': False, 'TRAIN_MAD_SCALE': False, 'TRAIN_QUANTILE_TRANSFORM': False, 'TRAIN_NORM_SCALE': False, 'TRAIN_RANK_NORM': True, 'TRAIN_CORR_REDUCTION': True, 'TRAIN_CORR_RANK_NORM': True}, nb_selected_features=50, cluster_method='coxPHMixture', pvalue_thres=0.01, classification_method='ALL_FEATURES', new_dim=100, training_tsv={'GE': 'rna_dummy.tsv', 'MIR': 'mir_dummy.tsv', 'METH': 'meth_dummy.tsv'}, metadata_usage=None, survival_tsv='survival_dummy.tsv', metadata_tsv=None, subset_training_with_meta={}, survival_flag={'patient_id': 'barcode', 'survival': 'days', 'event': 'recurrence'}, path_data='/content/DeepProg/simdeep/../examples/data/', level_dims_in=(), level_dims_out=(), loss='binary_crossentropy', optimizer='adam', act_reg=False, w_reg=False, dropout=0.5, data_split=None, node_selection='Cox-PH', cindex_thres=0.65, activation='tanh', clustering_omics=[], path_to_save_model='./', feature_selection_usage='individual', use_r_packages=False, alternative_embedding=None, kwargs_alternative_embedding={}, **additional_dataset_args)\n"," |  \n"," |  collect_cindex_for_full_dataset(self)\n"," |  \n"," |  collect_cindex_for_test_dataset(self)\n"," |  \n"," |  collect_cindex_for_test_fold(self)\n"," |  \n"," |  collect_cindex_for_training_dataset(self)\n"," |  \n"," |  collect_number_of_features_per_omic(self)\n"," |  \n"," |  collect_pvalue_on_full_dataset(self)\n"," |  \n"," |  collect_pvalue_on_test_dataset(self)\n"," |  \n"," |  collect_pvalue_on_test_fold(self)\n"," |  \n"," |  collect_pvalue_on_training_dataset(self)\n"," |  \n"," |  compute_c_indexes_for_full_dataset(self)\n"," |      return c-index using labels as predicat\n"," |  \n"," |  compute_c_indexes_for_test_dataset(self)\n"," |      return c-index using labels as predicat\n"," |  \n"," |  compute_c_indexes_multiple_for_test_dataset(self)\n"," |      Not Functionnal !\n"," |  \n"," |  compute_clusters_consistency_for_full_labels(self)\n"," |  \n"," |  compute_clusters_consistency_for_test_labels(self)\n"," |  \n"," |  compute_feature_scores_per_cluster(self, pval_thres=0.001)\n"," |  \n"," |  compute_pvalue_for_merged_test_fold(self)\n"," |  \n"," |  compute_survival_feature_scores_per_cluster(self, pval_thres=0.001, use_meta=False)\n"," |  \n"," |  evalutate_cluster_performance(self)\n"," |  \n"," |  fit(self, debug=False, verbose=False, pretrained_labels_files=[])\n"," |      if pretrained_labels_files, is given, the models are constructed using these labels\n"," |  \n"," |  fit_on_pretrained_label_file(self, labels_files=[], labels_files_folder='', file_name_regex='*.tsv', verbose=False, debug=False)\n"," |      fit a deepprog simdeep models without training autoencoders but using isntead  ID->labels files (one for each model instance)\n"," |  \n"," |  load_new_test_dataset(self, tsv_dict, fname_key=None, path_survival_file=None, normalization=None, debug=False, verbose=False, survival_flag=None, metadata_file=None)\n"," |  \n"," |  partial_fit(self, debug=False)\n"," |  \n"," |  plot_supervised_kernel_for_test_sets(self)\n"," |  \n"," |  plot_supervised_predicted_labels_for_test_sets(self, define_as_main_kernel=False, use_main_kernel=False)\n"," |  \n"," |  predict_labels_on_full_dataset(self)\n"," |  \n"," |  predict_labels_on_test_dataset(self)\n"," |  \n"," |  save_cv_models_classes(self, path_results='')\n"," |  \n"," |  save_models_classes(self, path_results='', use_cv_labels=False, use_test_labels=False)\n"," |  \n"," |  save_test_models_classes(self, path_results='')\n"," |  \n"," |  write_feature_score_per_cluster(self)\n"," |  \n"," |  write_logs(self)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"Lcfg8fCnlVWV"},"source":["# Location of the input matrices and survival file\n","from simdeep.config import PATH_DATA\n","\n","from collections import OrderedDict\n","\n","# Example tsv files\n","tsv_files = OrderedDict([\n","          ('MIR', 'mir_dummy.tsv'),\n","          ('METH', 'meth_dummy.tsv'),\n","          ('RNA', 'rna_dummy.tsv'),\n","])\n","\n","# File with survival event\n","survival_tsv = 'survival_dummy.tsv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmdFNs88lYoj"},"source":["project_name = 'stacked_TestProject'\n","epochs = 10 # Autoencoder epochs. Other hyperparameters can be fine-tuned. See the example files\n","seed = 3 # random seed used for reproducibility\n","nb_it = 5 # This is the number of models to be fitted using only a subset of the training data\n","nb_threads = 2 # These treads define the number of threads to be used to compute survival function\n","PATH_RESULTS = \"./\"\n","\n","boosting = SimDeepBoosting(\n","    nb_threads=nb_threads,\n","    nb_it=nb_it,\n","    split_n_fold=3,\n","    survival_tsv=survival_tsv,\n","    training_tsv=tsv_files,\n","    path_data=PATH_DATA,\n","    project_name=project_name,\n","    path_results=PATH_RESULTS,\n","    epochs=epochs,\n","    seed=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":792},"id":"yNeu8wMZlc4L","executionInfo":{"status":"error","timestamp":1633590662005,"user_tz":-480,"elapsed":74561,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"f63461a0-2597-4554-f9fe-df0006b04993"},"source":["# fit the model\n","boosting.fit()\n","\n","# predict & wirte the labels\n","boosting.predict_labels_on_test_dataset()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fit models...\n","Not subsetting training dataset.\n","model with random state:874 fitted\n","Not subsetting training dataset.\n","model with random state:664 fitted\n","Not subsetting training dataset.\n","model with random state:249 fitted\n","Not subsetting training dataset.\n","model with random state:643 fitted\n","Not subsetting training dataset.\n","model with random state:952 fitted\n","Results: [True, True, True, True, True]\n","5 models fitted\n","predict labels on test datasets...\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b60374883142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# predict & wirte the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_labels_on_test_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/DeepProg/simdeep/simdeep_boosting.py\u001b[0m in \u001b[0;36mpredict_labels_on_test_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m         res = self._do_class_selection(\n\u001b[1;32m    641\u001b[0m             \u001b[0mtest_labels_proba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             weights=self.cindex_test_folds)\n\u001b[0m\u001b[1;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DeepProg/simdeep/simdeep_boosting.py\u001b[0m in \u001b[0;36m_do_class_selection\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mreturn\u001b[0m  \u001b[0m_highest_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_selection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mean_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_selection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'weighted_mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_weighted_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DeepProg/simdeep/simdeep_boosting.py\u001b[0m in \u001b[0;36m_mean_proba\u001b[0;34m(proba)\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1731\u001b[0;31m     \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1732\u001b[0m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"SgDfQTt7liro","executionInfo":{"status":"error","timestamp":1633591035339,"user_tz":-480,"elapsed":3083,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"b451606e-3f65-45fb-b351-a83156664915"},"source":["boosting.plot_supervised_predicted_labels_for_test_sets()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["#### plotting supervised labels....\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-5765d24940c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_supervised_predicted_labels_for_test_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/DeepProg/simdeep/simdeep_boosting.py\u001b[0m in \u001b[0;36mplot_supervised_predicted_labels_for_test_sets\u001b[0;34m(self, define_as_main_kernel, use_main_kernel)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                          \u001b[0mtest_labels_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels_proba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m                          \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                          key='_' + self.test_fname_key)\n\u001b[0m\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot_supervised_kernel_for_test_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DeepProg/simdeep/simdeep_boosting.py\u001b[0m in \u001b[0;36m_from_model\u001b[0;34m(self, model, fname, *args, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 *args, **kwargs))\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_from_model_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DeepProg/simdeep/simdeep_analysis.py\u001b[0m in \u001b[0;36mplot_supervised_kernel_for_test_sets\u001b[0;34m(self, labels, labels_proba, dataset, key, use_main_kernel, test_labels, test_labels_proba, define_as_main_kernel)\u001b[0m\n\u001b[1;32m   1619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         activities, activities_test = self._predict_kde_matrix(\n\u001b[0;32m-> 1621\u001b[0;31m             labels_proba, dataset)\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'_supervised'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DeepProg/simdeep/simdeep_analysis.py\u001b[0m in \u001b[0;36m_predict_kde_matrix\u001b[0;34m(self, labels_proba, dataset)\u001b[0m\n\u001b[1;32m   1677\u001b[0m                 dataset.matrix_ref_array[key])\n\u001b[1;32m   1678\u001b[0m             matrix_test = encoder_array[key].predict(\n\u001b[0;32m-> 1679\u001b[0;31m                 dataset.matrix_test_array[key])\n\u001b[0m\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             survival_node_ids = self._look_for_survival_nodes(\n","\u001b[0;31mKeyError\u001b[0m: 'MIR'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"rroZBnVynKSn","executionInfo":{"status":"error","timestamp":1633591052454,"user_tz":-480,"elapsed":449,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"15cbd0e8-34b1-4cef-d337-80e41741c418"},"source":["boosting.plot_supervised_kernel_for_test_sets()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["plotting survival features using autoencoder...\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-eae430816210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_supervised_kernel_for_test_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/DeepProg/simdeep/simdeep_boosting.py\u001b[0m in \u001b[0;36mplot_supervised_kernel_for_test_sets\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plotting survival features using autoencoder...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m         \u001b[0mencoder_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_autoencoder_for_kernel_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m         activities, activities_test = self._predict_kde_matrices(\n\u001b[1;32m   1248\u001b[0m             encoder_key, self.dataset.matrix_test_array)\n","\u001b[0;32m/content/DeepProg/simdeep/simdeep_boosting.py\u001b[0m in \u001b[0;36m_create_autoencoder_for_kernel_plot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m         key_normalization = {\n\u001b[1;32m   1323\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_normalization\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_normalization\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         }\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRr5jJNqnUI2","executionInfo":{"status":"ok","timestamp":1633591103956,"user_tz":-480,"elapsed":2691,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"abafae84-626d-464d-fec4-138ba09bc1f2"},"source":["%cd DeepProg/data/\n","! gzip -d *.gz\n","%cd /content"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DeepProg/data\n","/content\n"]}]},{"cell_type":"code","metadata":{"id":"c62r5UZAngTb"},"source":["from simdeep.simdeep_boosting import SimDeepBoosting\n","from simdeep.config import PATH_THIS_FILE\n","\n","from collections import OrderedDict\n","from os.path import isfile\n","\n","# specify your data path\n","path_data = 'DeepProg/data/'\n","\n","assert(isfile(path_data + \"/meth.tsv\"))\n","assert(isfile(path_data + \"/rna.tsv\"))\n","assert(isfile(path_data + \"/mir.tsv\"))\n","\n","tsv_files = OrderedDict([\n","    ('MIR', 'mir.tsv'),\n","    ('METH', 'meth.tsv'),\n","    ('RNA', 'rna.tsv'),\n","])\n","\n","# The survival file located also in the same folder\n","survival_tsv = 'survival.tsv'\n","\n","assert(isfile(path_data + \"survival.tsv\"))\n","\n","# More attributes\n","PROJECT_NAME = 'HCC_dataset' # Name\n","EPOCHS = 10 # autoencoder fitting epoch\n","SEED = 10045 # random seed\n","nb_it = 10 # Number of submodels to be fitted\n","nb_threads = 2 # Number of python threads used to fit survival model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idNkOGI4nnge"},"source":["survival_flag = {\n","    'patient_id': 'Samples',\n","    'survival': 'days',\n","    'event': 'event'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUHG9R8onrqd","executionInfo":{"status":"ok","timestamp":1633591193236,"user_tz":-480,"elapsed":1616,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"b53d9fd9-5aa1-4746-915e-62bce86ce3b7"},"source":["import ray\n","ray.init(webui_host='0.0.0.0', num_cpus=3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-10-07 07:19:51,418\tINFO resource_spec.py:212 -- Starting Ray with 7.42 GiB memory available for workers and up to 3.72 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n","2021-10-07 07:19:52,055\tINFO services.py:1148 -- View the Ray dashboard at \u001b[1m\u001b[32m172.28.0.2:8265\u001b[39m\u001b[22m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'node_ip_address': '172.28.0.2',\n"," 'object_store_address': '/tmp/ray/session_2021-10-07_07-19-51_416694_232/sockets/plasma_store',\n"," 'raylet_socket_name': '/tmp/ray/session_2021-10-07_07-19-51_416694_232/sockets/raylet',\n"," 'redis_address': '172.28.0.2:50610',\n"," 'session_dir': '/tmp/ray/session_2021-10-07_07-19-51_416694_232',\n"," 'webui_url': '172.28.0.2:8265'}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9S41VxSQn2IY","executionInfo":{"status":"ok","timestamp":1633591686393,"user_tz":-480,"elapsed":482688,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"f37ea505-2d38-4161-9205-6047c9a6c31a"},"source":["# Instanciate a DeepProg instance\n","boosting = SimDeepBoosting(\n","    nb_threads=nb_threads,\n","    nb_it=nb_it,\n","    split_n_fold=3,\n","    survival_tsv=survival_tsv,\n","    training_tsv=tsv_files,\n","    path_data=path_data,\n","    project_name=PROJECT_NAME,\n","    path_results=path_data,\n","    epochs=EPOCHS,\n","    survival_flag=survival_flag,\n","    distribute=True,\n","    seed=SEED)\n","\n","boosting.fit()\n","\n","# predict labels of the training\n","\n","boosting.predict_labels_on_full_dataset()\n","boosting.compute_clusters_consistency_for_full_labels()\n","boosting.evalutate_cluster_performance()\n","boosting.collect_cindex_for_test_fold()\n","boosting.collect_cindex_for_full_dataset()\n","\n","boosting.compute_feature_scores_per_cluster()\n","boosting.write_feature_score_per_cluster()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fit models...\n"]},{"output_type":"stream","name":"stderr","text":["2021-10-07 07:20:09,595\tWARNING worker.py:1072 -- WARNING: 9 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n","2021-10-07 07:20:09,684\tWARNING worker.py:1072 -- WARNING: 10 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n","2021-10-07 07:20:13,031\tWARNING worker.py:1072 -- WARNING: 11 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[2m\u001b[36m(pid=1196)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1197)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1243)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1244)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1250)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1258)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1268)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1276)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1294)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1286)\u001b[0m #### trying to load optional R packages: The R package \"survcomp\" is not installed.\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1197)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1243)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1244)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1250)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1258)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1268)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1276)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1286)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1294)\u001b[0m Not subsetting training dataset.\n","\u001b[2m\u001b[36m(pid=1244)\u001b[0m model with random state:9868 fitted\n","\u001b[2m\u001b[36m(pid=1243)\u001b[0m model with random state:9953 fitted\n","\u001b[2m\u001b[36m(pid=1250)\u001b[0m model with random state:9938 fitted\n","\u001b[2m\u001b[36m(pid=1286)\u001b[0m model with random state:9758 fitted\n","\u001b[2m\u001b[36m(pid=1258)\u001b[0m model with random state:9786 fitted\n","\u001b[2m\u001b[36m(pid=1276)\u001b[0m model with random state:10009 fitted\n","\u001b[2m\u001b[36m(pid=1294)\u001b[0m model with random state:9478 fitted\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m model with random state:9358 fitted\n","\u001b[2m\u001b[36m(pid=1197)\u001b[0m model with random state:9358 fitted\n","\u001b[2m\u001b[36m(pid=1268)\u001b[0m model with random state:9689 fitted\n","Results: [True, True, True, True, True, True, True, True, True, True]\n","10 models fitted\n","predict labels on full datasets...\n","#### Report of assigned cluster for the full training dataset:\n","class: 0, number of samples :90\n","class: 1, number of samples :270\n","Figure saved in: DeepProg/data//HCC_dataset/HCC_dataset_KM_plot_boosting_full.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 3.960068318671064e-15\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 1.0391783665101225e-16\n","Figure saved in: DeepProg/data//HCC_dataset/HCC_dataset_proba_KM_plot_boosting_full.pdf\n","Cox-PH categorical p-value (Log-Rank) for inferred labels: 4.877554184651123e-11\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m file written: DeepProg/data//HCC_dataset/HCC_dataset_full_labels.tsv\n","Adj. Rand scores for full label: mean: 0.320613774677821 std: 0.17132713763309407\n","silhouette score: mean: 0.14599424600601196 std :0.022312115877866745\n","calinski harabasz score: mean: 36.8899044333524 std :8.029959319623591\n","C-index results for test fold: mean 0.5901668388868019 std 0.028695398970715814\n","c-index results for full dataset: mean 0.6400883813695202 std 0.015474870853286004\n","computing feature importance per cluster...\n","DeepProg/data//HCC_dataset/HCC_dataset_features_scores_per_clusters.tsv written\n","DeepProg/data//HCC_dataset/HCC_dataset_features_anticorrelated_scores_per_clusters.tsv written\n","No survival features detected. File: DeepProg/data//HCC_dataset/HCC_dataset_features_scores_per_clusters.tsv not writtten\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqzB6-Sgn5QF","executionInfo":{"status":"ok","timestamp":1633593337153,"user_tz":-480,"elapsed":90236,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"439735d5-249a-4140-c3bc-ba1e6c63c653"},"source":["boosting.load_new_test_dataset(\n","    {'RNA': 'rna.tsv'},\n","    'test_RNA_only',\n","    survival_tsv,\n",")\n","\n","boosting.predict_labels_on_test_dataset()\n","boosting.compute_c_indexes_for_test_dataset()\n","boosting.compute_clusters_consistency_for_test_labels()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading new test dataset test_RNA_only ...\n","Test dataset test_RNA_only loaded in 88.54431557655334 s\n","predict labels on test datasets...\n","#### Report of assigned cluster for TEST dataset test_RNA_only:\n","class: 0, number of samples :75\n","class: 1, number of samples :285\n","Figure saved in: DeepProg/data//HCC_dataset/HCC_dataset_test_RNA_only_KM_plot_boosting_test.pdf\n","Cox-PH p-value (Log-Rank) for inferred labels: 1.3476719963193849e-14\n","Cox-PH proba p-value (Log-Rank) for inferred labels: 1.0553359197292141e-16\n","Figure saved in: DeepProg/data//HCC_dataset/HCC_dataset_test_RNA_only_proba_KM_plot_boosting_test.pdf\n","Cox-PH categorical p-value (Log-Rank) for inferred labels: 3.4732097975683047e-09\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m file written: DeepProg/data//HCC_dataset/HCC_dataset_test_RNA_only_test_labels.tsv\n","c-index for boosting test dataset:0.6562903288881936\n","c-index proba for boosting test dataset:0.7104141410191233\n","c-index cat for boosting test dataset:0.6569160376989559\n","Adj. Rand scores for test label: mean: 0.3503688514074256 std: 0.13586935767977223\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.0,\n"," 0.23046914460038823,\n"," 0.2486239026348009,\n"," 0.3828222109749947,\n"," 0.3883424870273124,\n"," 0.3308574326423586,\n"," 0.32270953629246135,\n"," 0.27666215445020204,\n"," 0.487169307141657,\n"," 0.23046914460038823,\n"," 0.2486239026348009,\n"," 0.3828222109749947,\n"," 0.3883424870273124,\n"," 0.3308574326423586,\n"," 0.32270953629246135,\n"," 0.27666215445020204,\n"," 0.487169307141657,\n"," 0.26448852816033974,\n"," 0.18798373283710648,\n"," 0.25759348507401625,\n"," 0.3991700412792027,\n"," 0.13817489287063545,\n"," 0.1693506446101184,\n"," 0.2464335489784591,\n"," 0.2840980720475133,\n"," 0.32294627101715323,\n"," 0.2971319020055213,\n"," 0.2566097056491134,\n"," 0.3279671189235191,\n"," 0.26099334295388277,\n"," 0.5207485021459521,\n"," 0.30792274469645914,\n"," 0.360699784104968,\n"," 0.4286877338437607,\n"," 0.5451492076286052,\n"," 0.49497727216513543,\n"," 0.39658156505212466,\n"," 0.4257610168010659,\n"," 0.5142368153465704,\n"," 0.3041682428745118,\n"," 0.35169867211272643,\n"," 0.36086306386998745,\n"," 0.26952288102025457,\n"," 0.4188350260756267,\n"," 0.31849214766147227]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNPfQt3LvrqR","executionInfo":{"status":"ok","timestamp":1633593371440,"user_tz":-480,"elapsed":34295,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"d323133c-e940-4827-910b-736453d418cb"},"source":["boosting.plot_supervised_kernel_for_test_sets()\n","boosting.plot_supervised_predicted_labels_for_test_sets()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["plotting survival features using autoencoder...\n","preparing data for plotting...\n","Not subsetting training dataset.\n","fitting autoencoder for plotting...\n","fitting done!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"]},{"output_type":"stream","name":"stdout","text":["kde plot saved at:DeepProg/data//HCC_dataset/HCC_dataset_test_RNA_only_test_RNA_only_supervised_kdeplot.html\n","#### plotting supervised labels....\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m /usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m   FutureWarning\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m /usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m   FutureWarning\n","\u001b[2m\u001b[36m(pid=1196)\u001b[0m kde plot saved at:DeepProg/data//HCC_dataset/HCC_dataset_test_RNA_only_supervised_test_kdeplot.html\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YW9F--73vtYu","executionInfo":{"status":"ok","timestamp":1633593563230,"user_tz":-480,"elapsed":847,"user":{"displayName":"Indrik Wijaya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00208067985282844199"}},"outputId":"30ea3244-c05d-4280-8daf-1a0130f106d3"},"source":["! pwd\n","! du -hs DeepProg/data/HCC_dataset\n","! zip -r -X HCC_dataset.zip DeepProg/data/HCC_dataset"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","6.0M\tDeepProg/data/HCC_dataset\n","updating: DeepProg/data/HCC_dataset/ (stored 0%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_test_RNA_only_test_labels.tsv (deflated 64%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_features_anticorrelated_scores_per_clusters.tsv (deflated 64%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_full_labels.tsv (deflated 64%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_test_RNA_only_proba_KM_plot_boosting_test.pdf (deflated 26%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_test_RNA_only_KM_plot_boosting_test.pdf (deflated 26%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_KM_plot_boosting_full.pdf (deflated 26%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_test_RNA_only_test_RNA_only_supervised_kdeplot.html (deflated 84%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_test_RNA_only_supervised_test_kdeplot.html (deflated 83%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_features_scores_per_clusters.tsv (deflated 64%)\n","  adding: DeepProg/data/HCC_dataset/HCC_dataset_proba_KM_plot_boosting_full.pdf (deflated 26%)\n"]}]},{"cell_type":"code","metadata":{"id":"nQ_egQD1wQY0"},"source":[""],"execution_count":null,"outputs":[]}]}